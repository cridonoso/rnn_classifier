{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from core.plots import plot_cm\n",
    "from core.phased import PhasedLSTM\n",
    "from core.data import load_records\n",
    "from core.losses import custom_bce\n",
    "from core.metrics import custom_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = './runs/forced/fold_0/phased/'\n",
    "data_path = './data/records/forced/fold_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "        os.path.join(exp_path, 'model.h5'),\n",
    "        custom_objects={'PhasedLSTM': PhasedLSTM, \n",
    "                        'custom_bce':custom_bce,\n",
    "                        'custom_acc':custom_acc}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(data_path, 'test_samples.csv'))\n",
    "num_classes = len(metadata['alerceclass'].unique())\n",
    "test_batches = load_records(os.path.join(data_path, 'test'),\n",
    "                             16,\n",
    "                             max_obs=200,\n",
    "                             num_classes=num_classes,\n",
    "                             sampling=False,\n",
    "                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_bce(y_true, y_pred, sample_weight=None):\n",
    "    mask   = y_pred[...,-1]\n",
    "    y_pred = y_pred[...,:-1]\n",
    "\n",
    "    num_steps = tf.shape(y_pred)[1]\n",
    "\n",
    "    y_true = tf.expand_dims(y_true, 1)\n",
    "    y_true = tf.tile(y_true, [1, num_steps, 1])\n",
    "\n",
    "    losses = tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred)\n",
    "    losses = tf.multiply(losses, mask)\n",
    "    losses = tf.reduce_sum(losses, 1)\n",
    "    losses = tf.divide(losses, tf.reduce_sum(mask))\n",
    "    return tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.8810056  0.68829393 0.5618404  ... 0.04955821 0.04979631 0.05091546]\n",
      " [1.0118897  0.8520433  0.74179184 ... 0.0548726  0.05431003 0.05369619]\n",
      " [0.93474627 0.7612856  0.61366606 ... 0.1430687  0.14316066 0.14305869]\n",
      " ...\n",
      " [1.0088143  0.9023385  0.77803475 ... 0.03742049 0.03750362 0.03765081]\n",
      " [1.002216   0.8850013  0.7782019  ... 0.02976951 0.02880991 0.02767164]\n",
      " [1.0678198  1.0443408  1.0112319  ... 0.         0.         0.        ]], shape=(16, 200), dtype=float32)\n",
      "(16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 21:22:36.934439: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for batch, y in test_batches:\n",
    "    y_pred = model(batch)\n",
    "    custom_bce(y, y_pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,2, figsize=(16,5), sharey=True, gridspec_kw={'hspace': 0.1, 'wspace': 0.01}, dpi=300)\n",
    "\n",
    "# plot_cm(cm_0, axes[0], title=metrics_0['title'], class_names=cls_names_0, fontsize=10)\n",
    "# plot_cm(cm_1, axes[1], title=metrics_1['title'], class_names=cls_names_0, fontsize=10)\n",
    "# # plot_cm(cm_2, axes[2], title=metrics_2['title'], class_names=cls_names_0, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# print('Model & F1 & Recall & Precision & Accuracy \\\\\\\\\\hline')\n",
    "# for dictonary in [metrics_0,metrics_1]:\n",
    "#     print('{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} \\\\\\\\\\hline '.format(dictonary['title'],\n",
    "#                                                           dictonary['f1'],\n",
    "#                                                           dictonary['recall'],\n",
    "#                                                           dictonary['precision'],\n",
    "#                                                           dictonary['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
